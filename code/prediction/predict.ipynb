{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "# COMPARAÇÃO: COM vs SEM IMPUTAÇÃO\n",
      "# Modelos: LSTM e GRU\n",
      "# Dados imputados: ../../datasets/multivariada-imputed-selecionados\n",
      "# Dados não imputados: ../../datasets/multivariada-post-process\n",
      "# 12 timesteps passados para prever 1 passo à frente\n",
      "################################################################################\n",
      "\n",
      "Encontrados 406 pares de arquivos correspondentes\n",
      "\n",
      "============================================================\n",
      "Processando link: ac-ap\n",
      "============================================================\n",
      "Encontrando melhores parâmetros universais...\n",
      "  Novos melhores parâmetros: RMSE médio=0.1361, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1357, params={'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1353, params={'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1352, params={'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1351, params={'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "Melhores parâmetros universais encontrados: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "\n",
      "  Avaliando LSTM...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    LSTM - Com imputação: 0.1370\n",
      "    LSTM - Sem imputação: 0.1277\n",
      "\n",
      "  Avaliando GRU...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    GRU - Com imputação: 0.1361\n",
      "    GRU - Sem imputação: 0.1255\n",
      "  Predições salvas em: comparison_predictions_ac-ap.csv\n",
      "\n",
      "============================================================\n",
      "Processando link: ac-ba\n",
      "============================================================\n",
      "Encontrando melhores parâmetros universais...\n",
      "  Novos melhores parâmetros: RMSE médio=0.1536, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1531, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1525, params={'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1524, params={'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1523, params={'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1520, params={'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1516, params={'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1510, params={'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "Melhores parâmetros universais encontrados: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "\n",
      "  Avaliando LSTM...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    LSTM - Com imputação: 0.1590\n",
      "    LSTM - Sem imputação: 0.1145\n",
      "\n",
      "  Avaliando GRU...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    GRU - Com imputação: 0.1474\n",
      "    GRU - Sem imputação: 0.1151\n",
      "  Predições salvas em: comparison_predictions_ac-ba.csv\n",
      "\n",
      "============================================================\n",
      "Processando link: ac-ce\n",
      "============================================================\n",
      "Encontrando melhores parâmetros universais...\n",
      "  Novos melhores parâmetros: RMSE médio=0.1230, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1223, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1218, params={'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1207, params={'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "Melhores parâmetros universais encontrados: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "\n",
      "  Avaliando LSTM...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    LSTM - Com imputação: 0.1254\n",
      "    LSTM - Sem imputação: 0.0894\n",
      "\n",
      "  Avaliando GRU...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    GRU - Com imputação: 0.1371\n",
      "    GRU - Sem imputação: 0.0937\n",
      "  Predições salvas em: comparison_predictions_ac-ce.csv\n",
      "\n",
      "============================================================\n",
      "Processando link: ac-es\n",
      "============================================================\n",
      "Encontrando melhores parâmetros universais...\n",
      "  Novos melhores parâmetros: RMSE médio=0.1017, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1002, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.0994, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.0993, params={'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.0992, params={'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.0991, params={'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.0990, params={'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "Melhores parâmetros universais encontrados: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "\n",
      "  Avaliando LSTM...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    LSTM - Com imputação: 0.1002\n",
      "    LSTM - Sem imputação: 0.0750\n",
      "\n",
      "  Avaliando GRU...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    GRU - Com imputação: 0.0987\n",
      "    GRU - Sem imputação: 0.0732\n",
      "  Predições salvas em: comparison_predictions_ac-es.csv\n",
      "\n",
      "============================================================\n",
      "Processando link: ac-go\n",
      "============================================================\n",
      "Encontrando melhores parâmetros universais...\n",
      "  Novos melhores parâmetros: RMSE médio=0.1208, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1186, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1177, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1173, params={'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "Melhores parâmetros universais encontrados: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "\n",
      "  Avaliando LSTM...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    LSTM - Com imputação: 0.1195\n",
      "    LSTM - Sem imputação: 0.0981\n",
      "\n",
      "  Avaliando GRU...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "    GRU - Com imputação: 0.1159\n",
      "    GRU - Sem imputação: 0.0925\n",
      "  Predições salvas em: comparison_predictions_ac-go.csv\n",
      "\n",
      "============================================================\n",
      "Processando link: ac-ma\n",
      "============================================================\n",
      "Encontrando melhores parâmetros universais...\n",
      "  Novos melhores parâmetros: RMSE médio=0.1028, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.1021, params={'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "Melhores parâmetros universais encontrados: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 16, 'epochs': 100}\n",
      "\n",
      "  Avaliando LSTM...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "WARNING:tensorflow:5 out of the last 56 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B0997B0E00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "    LSTM - Com imputação: 0.1031\n",
      "    LSTM - Sem imputação: 0.0753\n",
      "\n",
      "  Avaliando GRU...\n",
      "    Com imputação...\n",
      "    Sem imputação...\n",
      "WARNING:tensorflow:5 out of the last 56 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001AFFE9384A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "    GRU - Com imputação: 0.1058\n",
      "    GRU - Sem imputação: 0.0878\n",
      "  Predições salvas em: comparison_predictions_ac-ma.csv\n",
      "\n",
      "============================================================\n",
      "Processando link: ac-ms\n",
      "============================================================\n",
      "Encontrando melhores parâmetros universais...\n",
      "  Novos melhores parâmetros: RMSE médio=0.0965, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.0956, params={'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n",
      "  Novos melhores parâmetros: RMSE médio=0.0949, params={'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração do TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Fixar seeds para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def find_matching_files(imputed_folder, non_imputed_folder):\n",
    "    \"\"\"\n",
    "    Encontra arquivos correspondentes entre as pastas com e sem imputação\n",
    "    Retorna dicionário com {link: {'imputed': path, 'non_imputed': path}}\n",
    "    \"\"\"\n",
    "    # Buscar arquivos imputados (formato: ac-am_stacking.csv)\n",
    "    imputed_files = glob.glob(os.path.join(imputed_folder, \"*_stacking.csv\"))\n",
    "    \n",
    "    # Buscar arquivos não imputados (formato: ac-am_merged.csv)\n",
    "    non_imputed_files = glob.glob(os.path.join(non_imputed_folder, \"*_merged.csv\"))\n",
    "    \n",
    "    # Criar mapeamento de links para arquivos não imputados\n",
    "    non_imputed_dict = {}\n",
    "    for file_path in non_imputed_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        link = filename.replace('_merged.csv', '')\n",
    "        non_imputed_dict[link] = file_path\n",
    "    \n",
    "    # Combinar arquivos correspondentes\n",
    "    matched_files = {}\n",
    "    \n",
    "    for imputed_file in imputed_files:\n",
    "        filename = os.path.basename(imputed_file)\n",
    "        link = filename.replace('_stacking.csv', '')\n",
    "        \n",
    "        # Verificar se existe arquivo correspondente sem imputação\n",
    "        if link in non_imputed_dict:\n",
    "            matched_files[link] = {\n",
    "                'imputed': imputed_file,\n",
    "                'non_imputed': non_imputed_dict[link]\n",
    "            }\n",
    "    \n",
    "    print(f\"Encontrados {len(matched_files)} pares de arquivos correspondentes\")\n",
    "    return matched_files\n",
    "\n",
    "\n",
    "def prepare_univariate_sequences(data, n_steps, target_col='Vazao_BBR'):\n",
    "    \"\"\"\n",
    "    Prepara sequências UNIVARIADAS para LSTM/GRU usando apenas Vazao_BBR\n",
    "    A predição é feita 1 passo à frente (next timestep)\n",
    "    \"\"\"\n",
    "    # Usar apenas a coluna Vazao_BBR\n",
    "    vazao_data = data[[target_col]].values\n",
    "    \n",
    "    # Normalizar dados\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(vazao_data)\n",
    "    \n",
    "    X, y = [], []\n",
    "    indices = []  # Para rastrear índices originais\n",
    "    \n",
    "    for i in range(n_steps, len(scaled_data)):\n",
    "        # Input: n_steps valores anteriores de Vazao_BBR\n",
    "        X.append(scaled_data[i-n_steps:i, 0])\n",
    "        # Target: próximo valor de Vazao_BBR\n",
    "        y.append(scaled_data[i, 0])\n",
    "        indices.append(i)\n",
    "    \n",
    "    # Reformatar X para ter shape (samples, timesteps, features)\n",
    "    # Para univariado: features = 1\n",
    "    X = np.array(X)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler, indices\n",
    "\n",
    "\n",
    "def prepare_non_imputed_sequences(data, n_steps, target_col='Vazao_BBR'):\n",
    "    \"\"\"\n",
    "    Prepara sequências para dados não imputados, removendo valores -1\n",
    "    \"\"\"\n",
    "    # Filtrar dados: remover linhas onde Vazao_BBR = -1\n",
    "    valid_data = data[data[target_col] != -1].copy()\n",
    "    \n",
    "    if len(valid_data) == 0:\n",
    "        return np.array([]), np.array([]), None, []\n",
    "    \n",
    "    # Usar apenas a coluna Vazao_BBR\n",
    "    vazao_data = valid_data[[target_col]].values\n",
    "    \n",
    "    # Normalizar dados\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(vazao_data)\n",
    "    \n",
    "    X, y = [], []\n",
    "    indices = []  # Para rastrear índices originais (após filtragem)\n",
    "    \n",
    "    for i in range(n_steps, len(scaled_data)):\n",
    "        # Input: n_steps valores anteriores de Vazao_BBR\n",
    "        X.append(scaled_data[i-n_steps:i, 0])\n",
    "        # Target: próximo valor de Vazao_BBR\n",
    "        y.append(scaled_data[i, 0])\n",
    "        indices.append(i)  # Índices relativos ao valid_data\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        return np.array([]), np.array([]), scaler, []\n",
    "    \n",
    "    # Reformatar X para ter shape (samples, timesteps, features)\n",
    "    X = np.array(X)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler, indices\n",
    "\n",
    "\n",
    "def create_lstm_model(input_shape, units, dropout, learning_rate):\n",
    "    \"\"\"\n",
    "    Cria modelo LSTM para predição univariada\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(units, activation='relu', return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units // 2, activation='relu'),\n",
    "        Dropout(dropout),\n",
    "        Dense(units // 4, activation='relu'),\n",
    "        Dense(1)  # Predição de 1 valor (Vazao_BBR no próximo timestep)\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_gru_model(input_shape, units, dropout, learning_rate):\n",
    "    \"\"\"\n",
    "    Cria modelo GRU para predição univariada\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        GRU(units, activation='relu', return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(dropout),\n",
    "        GRU(units // 2, activation='relu'),\n",
    "        Dropout(dropout),\n",
    "        Dense(units // 4, activation='relu'),\n",
    "        Dense(1)  # Predição de 1 valor (Vazao_BBR no próximo timestep)\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula RMSE entre valores reais e preditos\n",
    "    \"\"\"\n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, model_type, params):\n",
    "    \"\"\"\n",
    "    Treina e avalia um modelo\n",
    "    \"\"\"\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        return float('inf'), None\n",
    "    \n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        model = create_lstm_model(input_shape, params['units'], params['dropout'], params['learning_rate'])\n",
    "    else:\n",
    "        model = create_gru_model(input_shape, params['units'], params['dropout'], params['learning_rate'])\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    predictions = model.predict(X_test, verbose=0).flatten()\n",
    "    \n",
    "    # Calcular RMSE\n",
    "    rmse = calculate_rmse(y_test, predictions)\n",
    "    \n",
    "    return rmse, model\n",
    "\n",
    "\n",
    "def find_best_universal_params(imputed_file, non_imputed_file, n_steps, param_grid):\n",
    "    \"\"\"\n",
    "    Encontra os melhores parâmetros universais usando dados imputados como referência\n",
    "    \"\"\"\n",
    "    print(f\"Encontrando melhores parâmetros universais...\")\n",
    "    \n",
    "    # Carregar dados imputados (usar como referência principal)\n",
    "    df_imputed = pd.read_csv(imputed_file)\n",
    "    df_imputed['Data'] = pd.to_datetime(df_imputed['Data'])\n",
    "    df_imputed = df_imputed.sort_values('Data').reset_index(drop=True)\n",
    "    \n",
    "    # Preparar sequências dos dados imputados\n",
    "    X_imp, y_imp, scaler_imp, indices_imp = prepare_univariate_sequences(df_imputed, n_steps)\n",
    "    \n",
    "    if len(X_imp) == 0:\n",
    "        print(\"Dados imputados insuficientes para treinamento\")\n",
    "        return None\n",
    "    \n",
    "    # Split treino/teste para dados imputados\n",
    "    split_idx = int(len(X_imp) * 0.8)\n",
    "    X_train_imp, X_test_imp = X_imp[:split_idx], X_imp[split_idx:]\n",
    "    y_train_imp, y_test_imp = y_imp[:split_idx], y_imp[split_idx:]\n",
    "    \n",
    "    # Testar combinações de parâmetros para ambos os modelos\n",
    "    best_combination = None\n",
    "    best_avg_rmse = float('inf')\n",
    "    \n",
    "    for units in param_grid['units']:\n",
    "        for dropout in param_grid['dropout']:\n",
    "            for lr in param_grid['learning_rate']:\n",
    "                for batch_size in param_grid['batch_size']:\n",
    "                    params = {\n",
    "                        'units': units,\n",
    "                        'dropout': dropout,\n",
    "                        'learning_rate': lr,\n",
    "                        'batch_size': batch_size,\n",
    "                        'epochs': param_grid['epochs']\n",
    "                    }\n",
    "                    \n",
    "                    try:\n",
    "                        # Testar LSTM com dados imputados\n",
    "                        lstm_rmse_imp, _ = train_and_evaluate(\n",
    "                            X_train_imp, y_train_imp, X_test_imp, y_test_imp, 'lstm', params\n",
    "                        )\n",
    "                        \n",
    "                        # Testar GRU com dados imputados\n",
    "                        gru_rmse_imp, _ = train_and_evaluate(\n",
    "                            X_train_imp, y_train_imp, X_test_imp, y_test_imp, 'gru', params\n",
    "                        )\n",
    "                        \n",
    "                        avg_rmse = (lstm_rmse_imp + gru_rmse_imp) / 2\n",
    "                        \n",
    "                        if avg_rmse < best_avg_rmse:\n",
    "                            best_avg_rmse = avg_rmse\n",
    "                            best_combination = params\n",
    "                            print(f\"  Novos melhores parâmetros: RMSE médio={avg_rmse:.4f}, params={params}\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"  Erro com params {params}: {e}\")\n",
    "                        continue\n",
    "    \n",
    "    if best_combination:\n",
    "        print(f\"Melhores parâmetros universais encontrados: {best_combination}\")\n",
    "    else:\n",
    "        print(\"Não foi possível encontrar parâmetros adequados\")\n",
    "    \n",
    "    return best_combination\n",
    "\n",
    "\n",
    "def evaluate_single_dataset(file_path, n_steps, model_type, best_params, is_imputed=True):\n",
    "    \"\"\"\n",
    "    Avalia um modelo em um único dataset (com ou sem imputação)\n",
    "    \"\"\"\n",
    "    # Carregar dados\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Data'] = pd.to_datetime(df['Data'])\n",
    "    df = df.sort_values('Data').reset_index(drop=True)\n",
    "    \n",
    "    # Preparar sequências baseado no tipo de dados\n",
    "    if is_imputed:\n",
    "        X, y, scaler, indices = prepare_univariate_sequences(df, n_steps)\n",
    "    else:\n",
    "        X, y, scaler, indices = prepare_non_imputed_sequences(df, n_steps)\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(f\"  Dados insuficientes após preparação\")\n",
    "        return float('inf'), best_params, None, indices\n",
    "    \n",
    "    # Split treino/teste (80/20)\n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    # Treinar e avaliar com parâmetros fixos\n",
    "    rmse, model = train_and_evaluate(X_train, y_train, X_test, y_test, model_type, best_params)\n",
    "    \n",
    "    # Fazer predições para todo o dataset se possível\n",
    "    predictions = None\n",
    "    if len(X) > 0:\n",
    "        # Treinar modelo final com todos os dados de treino\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        if model_type == 'lstm':\n",
    "            final_model = create_lstm_model(input_shape, best_params['units'], \n",
    "                                          best_params['dropout'], best_params['learning_rate'])\n",
    "        else:\n",
    "            final_model = create_gru_model(input_shape, best_params['units'], \n",
    "                                         best_params['dropout'], best_params['learning_rate'])\n",
    "        \n",
    "        final_model.fit(X_train, y_train, epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], validation_split=0.2,\n",
    "                       callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predições em todo o dataset\n",
    "        all_predictions = final_model.predict(X, verbose=0).flatten()\n",
    "        \n",
    "        # Desnormalizar predições\n",
    "        predictions_denorm = scaler.inverse_transform(all_predictions.reshape(-1, 1)).flatten()\n",
    "        predictions = predictions_denorm\n",
    "    \n",
    "    return rmse, best_params, predictions, indices\n",
    "\n",
    "\n",
    "def compare_imputation_vs_non_imputation(imputed_folder, non_imputed_folder, n_steps=12):\n",
    "    \"\"\"\n",
    "    Compara performance de LSTM e GRU com e sem imputação\n",
    "    \"\"\"\n",
    "    # Configuração de hiperparâmetros\n",
    "    param_grid = {\n",
    "        'units': [32, 64, 128],\n",
    "        'dropout': [0.1, 0.2, 0.3],\n",
    "        'learning_rate': [0.001, 0.0005],\n",
    "        'batch_size': [16, 32],\n",
    "        'epochs': 100\n",
    "    }\n",
    "    \n",
    "    # Encontrar arquivos correspondentes\n",
    "    matched_files = find_matching_files(imputed_folder, non_imputed_folder)\n",
    "    \n",
    "    if not matched_files:\n",
    "        print(\"Nenhum par de arquivos correspondente encontrado!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for link, files in matched_files.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processando link: {link}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Encontrar melhores parâmetros universais para este link\n",
    "        best_params = find_best_universal_params(\n",
    "            files['imputed'], files['non_imputed'], n_steps, param_grid\n",
    "        )\n",
    "        \n",
    "        if not best_params:\n",
    "            print(f\"  Não foi possível encontrar parâmetros para {link}. Pulando...\")\n",
    "            continue\n",
    "        \n",
    "        link_results = {}\n",
    "        \n",
    "        # Avaliar cada combinação: modelo × tipo de dados\n",
    "        for model_type in ['lstm', 'gru']:\n",
    "            print(f\"\\n  Avaliando {model_type.upper()}...\")\n",
    "            \n",
    "            # Com imputação\n",
    "            print(f\"    Com imputação...\")\n",
    "            rmse_imputed, _, preds_imp, indices_imp = evaluate_single_dataset(\n",
    "                files['imputed'], n_steps, model_type, best_params, is_imputed=True\n",
    "            )\n",
    "            \n",
    "            # Sem imputação\n",
    "            print(f\"    Sem imputação...\")\n",
    "            rmse_non_imputed, _, preds_non_imp, indices_non_imp = evaluate_single_dataset(\n",
    "                files['non_imputed'], n_steps, model_type, best_params, is_imputed=False\n",
    "            )\n",
    "            \n",
    "            link_results[model_type] = {\n",
    "                'rmse_imputed': rmse_imputed,\n",
    "                'rmse_non_imputed': rmse_non_imputed,\n",
    "                'predictions_imputed': preds_imp,\n",
    "                'predictions_non_imputed': preds_non_imp,\n",
    "                'indices_imputed': indices_imp,\n",
    "                'indices_non_imputed': indices_non_imp\n",
    "            }\n",
    "            \n",
    "            print(f\"    {model_type.upper()} - Com imputação: {rmse_imputed:.4f}\")\n",
    "            print(f\"    {model_type.upper()} - Sem imputação: {rmse_non_imputed:.4f}\")\n",
    "            \n",
    "            # Calcular melhoria da imputação\n",
    "            if rmse_non_imputed != float('inf') and rmse_imputed != float('inf'):\n",
    "                improvement = ((rmse_non_imputed - rmse_imputed) / rmse_non_imputed) * 100\n",
    "            else:\n",
    "                improvement = 0\n",
    "            \n",
    "            # Salvar resultado\n",
    "            results.append({\n",
    "                'Link': link,\n",
    "                'Model': model_type.upper(),\n",
    "                'RMSE_Com_Imputacao': rmse_imputed,\n",
    "                'RMSE_Sem_Imputacao': rmse_non_imputed,\n",
    "                'Melhoria_%': improvement,\n",
    "                'Params': str(best_params)\n",
    "            })\n",
    "        \n",
    "        # Salvar predições para análise posterior\n",
    "        save_predictions(link, files['imputed'], link_results)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def save_predictions(link, original_file, results):\n",
    "    \"\"\"\n",
    "    Salva predições em arquivos CSV para análise\n",
    "    \"\"\"\n",
    "    # Carregar dados originais\n",
    "    df_original = pd.read_csv(original_file)\n",
    "    df_original['Data'] = pd.to_datetime(df_original['Data'])\n",
    "    df_original = df_original.sort_values('Data').reset_index(drop=True)\n",
    "    \n",
    "    # Criar dataframe com predições\n",
    "    df_pred = df_original.copy()\n",
    "    \n",
    "    for model_type in ['lstm', 'gru']:\n",
    "        # Predições com imputação\n",
    "        pred_imp = results[model_type]['predictions_imputed']\n",
    "        indices_imp = results[model_type]['indices_imputed']\n",
    "        \n",
    "        if pred_imp is not None and len(pred_imp) > 0:\n",
    "            df_pred[f'Predict_{model_type.upper()}_Imputed'] = np.nan\n",
    "            df_pred.loc[indices_imp, f'Predict_{model_type.upper()}_Imputed'] = pred_imp\n",
    "    \n",
    "    # Salvar arquivo\n",
    "    output_file = f\"comparison_predictions_{link}.csv\"\n",
    "    df_pred.to_csv(output_file, index=False)\n",
    "    print(f\"  Predições salvas em: {output_file}\")\n",
    "\n",
    "\n",
    "def main(imputed_folder, non_imputed_folder, n_steps=12):\n",
    "    \"\"\"\n",
    "    Função principal para executar comparação\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"# COMPARAÇÃO: COM vs SEM IMPUTAÇÃO\")\n",
    "    print(f\"# Modelos: LSTM e GRU\")\n",
    "    print(f\"# Dados imputados: {imputed_folder}\")\n",
    "    print(f\"# Dados não imputados: {non_imputed_folder}\")\n",
    "    print(f\"# {n_steps} timesteps passados para prever 1 passo à frente\")\n",
    "    print(f\"{'#'*80}\\n\")\n",
    "    \n",
    "    # Executar comparação\n",
    "    results_df = compare_imputation_vs_non_imputation(\n",
    "        imputed_folder, non_imputed_folder, n_steps\n",
    "    )\n",
    "    \n",
    "    if results_df.empty:\n",
    "        print(\"Nenhum resultado foi gerado!\")\n",
    "        return results_df\n",
    "    \n",
    "    # Filtrar casos válidos\n",
    "    valid_results = results_df[\n",
    "        (results_df['RMSE_Com_Imputacao'] != float('inf')) & \n",
    "        (results_df['RMSE_Sem_Imputacao'] != float('inf'))\n",
    "    ].copy()\n",
    "    \n",
    "    # Salvar resultados\n",
    "    output_file = 'resultados_comparacao_imputacao.csv'\n",
    "    valid_results.to_csv(output_file, index=False)\n",
    "    print(f\"\\nResultados salvos em: {output_file}\")\n",
    "    \n",
    "    # Mostrar resumo\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESUMO DA COMPARAÇÃO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if len(valid_results) > 0:\n",
    "        print(valid_results.to_string(index=False))\n",
    "        \n",
    "        # Estatísticas\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"ESTATÍSTICAS GERAIS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Total de comparações válidas: {len(valid_results)}\")\n",
    "        print(f\"Melhoria média da imputação: {valid_results['Melhoria_%'].mean():.2f}%\")\n",
    "        print(f\"Melhoria mediana da imputação: {valid_results['Melhoria_%'].median():.2f}%\")\n",
    "        print(f\"Casos com melhoria positiva: {len(valid_results[valid_results['Melhoria_%'] > 0])}\")\n",
    "        print(f\"Casos com piora: {len(valid_results[valid_results['Melhoria_%'] < 0])}\")\n",
    "        \n",
    "        # Por modelo\n",
    "        for model in ['LSTM', 'GRU']:\n",
    "            model_results = valid_results[valid_results['Model'] == model]\n",
    "            if len(model_results) > 0:\n",
    "                print(f\"\\n{model}:\")\n",
    "                print(f\"  Melhoria média: {model_results['Melhoria_%'].mean():.2f}%\")\n",
    "                print(f\"  Melhores casos: {len(model_results[model_results['Melhoria_%'] > 0])}\")\n",
    "    else:\n",
    "        print(\"Nenhum resultado válido para análise\")\n",
    "    \n",
    "    return valid_results\n",
    "\n",
    "\n",
    "# Exemplo de uso:\n",
    "if __name__ == \"__main__\":\n",
    "    # Substitua pelos caminhos das suas pastas\n",
    "    IMPUTED_FOLDER = \"../../datasets/multivariada-imputed-selecionados\"\n",
    "    NON_IMPUTED_FOLDER = \"../../datasets/multivariada-post-process\"  # Ajuste este caminho\n",
    "    \n",
    "    # Executar comparação\n",
    "    results = main(IMPUTED_FOLDER, NON_IMPUTED_FOLDER, n_steps=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
